import OpenAI from 'openai';
import { AssistantStreamEvent } from 'openai/resources/beta/assistants';
import events from 'events';

import { IAI_Quote_Create, IAI_Quote_Fetch } from '@/types/openai';
import { Metals_fetch } from '@/actions/metals';
import { QuotesModel, Quotes_upsert } from '@/actions/quotes';

const AI = new OpenAI({ apiKey: process.env.OPENAI_API_KEY }).beta;
const ASSISTANT_ID = process.env.OPENAI_ASSISTANT_ID || '';

// File state to determine if AI used our function calling or not
// ideally we'd use redis if this app gets really big to scale but this should suffice
const QUOTES_GENERATED: { [key: string]: boolean } = {};

const getFunctionCallingTool = async () => {
  try {
    const assistant = await AI.assistants.retrieve(ASSISTANT_ID);

    // Only one function calling tool should exist on this assistant.
    const tool = assistant.tools[0];

    return tool;
  } catch (error) {
    console.error(error);
    throw error;
  }
};

const generateQuote = async (quoteArgs: IAI_Quote_Fetch): Promise<string> => {
  try {
    const { metadata } = quoteArgs;
    const { prompt, client_email } = metadata;
    const { quantity_requested = 1 } = quoteArgs;
    const metals = await Metals_fetch(quoteArgs);

    if (!metals || !metals.length) {
      return `Looks like we don't have ${quoteArgs.material} in our current inventory`;
    }

    const quotePromises = metals.map((metal) => {
      const { material, shape, grade, finish, inventory, dimensions } = metal;
      const totalPrice = (inventory.price * quantity_requested) / 100;
      const quoteMessage = `Here's what we can offer you on ${material} ${shape}s.\n
      Grade: ${grade}
      Finish: ${finish}
      Dimensions: ${dimensions.toString()} 
      Total Price: $${totalPrice}\n
      Price per Unit: $${inventory.price / 100}\n
      Quantity: ${quantity_requested}\n
      `;

      const toolOutputsQuote = {
        client_email,
        cf_admin_email: 'chris@cloudforgesoftware.com',
        prompt,
        message: quoteMessage,
        total_price: totalPrice,
        metal_price: inventory.price,
        quantity: quantity_requested,
        dimensions
      };

      return toolOutputsQuote;
    });

    const quotes = await Promise.all(quotePromises);

    return JSON.stringify(quotes);
  } catch (error) {
    console.error('Error in generateQuote: ', error);
    throw error;
  }
};

const createQuote = async (quote: IAI_Quote_Create) => {
  try {
    const quoteMessage = quote.message;
    const { client_email, prompt } = quote.metadata;
    const quoteModel = QuotesModel({
      client_email,
      prompt,
      message: quoteMessage
    });
    const newQuote = await Quotes_upsert(quoteModel);

    return newQuote;
  } catch (error) {
    console.error(error);
    throw error;
  }
};

const eventHandler = new events.EventEmitter();
eventHandler.on('event', async (event: AssistantStreamEvent) => {
  try {
    console.log(event);
    const { event: ai_event, data } = event;

    // AI needs to call our function in order to continue
    if (ai_event === 'thread.run.requires_action' && data.required_action) {
      const toolOutputs = await Promise.all(
        data.required_action.submit_tool_outputs.tool_calls.map(
          async (tool) => {
            const quoteArgs = JSON.parse(tool.function.arguments);
            // in case we want to add more function calling in the future
            if (tool.function.name === 'get_quote') {
              const quoteOutput = await generateQuote({
                ...quoteArgs,
                metadata: data.metadata
              });
              QUOTES_GENERATED[data.thread_id] = true;

              return {
                tool_call_id: tool.id,
                output: quoteOutput
              };
            }

            // i guess we need this for a catch all to make typescript happy?
            return {
              tool_call_id: tool.id
            };
          }
        )
      );

      const toolOutputStream = AI.threads.runs.submitToolOutputsStream(
        data.thread_id,
        data.id,
        {
          tool_outputs: toolOutputs
        }
      );

      for await (const event of toolOutputStream) {
        eventHandler.emit('event', event);
      }
    }

    // a message quote has been generated by AI so let's save that info in our db.
    if (
      ai_event === 'thread.message.completed' &&
      data.content[0].type === 'text' &&
      QUOTES_GENERATED[data.thread_id]
    ) {
      // need to retrieve thread obj since messages don't contain metadata in streaming
      const api_thread_res = await AI.threads.retrieve(data.thread_id);
      const metadata = api_thread_res.metadata as IAI_Quote_Create['metadata'];
      const message = data.content[0].text.value;
      await createQuote({ metadata, message });

      // save memory if this app ever scales in the future!
      delete QUOTES_GENERATED[data.thread_id];
    }
  } catch (error) {
    console.error('Error handling event:', error);
  }
});

const ai_sendMessage = async (
  message: string,
  client_email: string
): Promise<void> => {
  try {
    const tool = await getFunctionCallingTool();

    const threadStream = await AI.threads.createAndRun({
      assistant_id: ASSISTANT_ID,
      thread: {
        messages: [
          {
            role: 'user',
            content: message,
            metadata: {
              prompt: message,
              client_email
            }
          }
        ]
      },
      tools: [tool],
      metadata: {
        prompt: message,
        client_email
      },
      stream: true
    });

    for await (const event of threadStream) {
      eventHandler.emit('event', event);
    }
  } catch (error) {
    console.error(error);
    throw error;
  }
};

export { ai_sendMessage };
